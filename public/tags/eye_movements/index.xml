<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eye_movements | R. Calen Walshe</title>
    <link>/calenwalshe.github.io/tags/eye_movements/</link>
      <atom:link href="/calenwalshe.github.io/tags/eye_movements/index.xml" rel="self" type="application/rss+xml" />
    <description>eye_movements</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 21 Sep 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/calenwalshe.github.io/img/icon-192.png</url>
      <title>eye_movements</title>
      <link>/calenwalshe.github.io/tags/eye_movements/</link>
    </image>
    
    <item>
      <title>Predicting gaze with reinforcement learning</title>
      <link>/calenwalshe.github.io/project/reinforcement-learning/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/calenwalshe.github.io/project/reinforcement-learning/</guid>
      <description>&lt;p&gt;We developed an approach to predicting eye movements during category learning tasks. One of the central roles of eye movements is to sample information from the environment in a way that supports ongoing tasks and such that the information is sampled at the appropriate time.&lt;/p&gt;

&lt;p&gt;During classification tasks information from different spatial locations must often be used to determine the specific features of an object that are relevant for placing it in the appropriate category. When categories and objects are well known to the object they will typically know where to look on the object to classify it appropriately. However, when encountering a new object, or a new &lt;em&gt;type&lt;/em&gt; of object, it isn&amp;rsquo;t clear which features are relevant. In this case, the observer must learn the features that should be used to classify the object correctly.&lt;/p&gt;

&lt;p&gt;In this work, we show that a reinforcement learning approach to learning which locations to look at in order to perform well in the classification task does a good job of predicting actual human learning in classification experiments. This work supports the idea that reinforcement learning provides a good model for how humans select actions.&lt;/p&gt;

&lt;p&gt;Barnes, J. I., McColeman, C., Stepanova, E., Blair, M. R., &amp;amp; Walshe, R. C. (2014). RLAttn: An actor-critic model of eye movements during category learning. In Proceedings of the Annual Meeting of the Cognitive Science Society (Vol. 36, No. 36).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian optimal search</title>
      <link>/calenwalshe.github.io/project/search/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/calenwalshe.github.io/project/search/</guid>
      <description>&lt;p&gt;Searching the environment in a fast and efficient manner is a critical
capability for humans and many other animals. Normally, multiple fixations
are used to identify and localize targets. However, in the special case of
covert search the target must be identified and localized within a single
fixation. Here we present a theory of covert search that takes into account
the statistical variation in background images, the falloff in resolution and
sampling with retinal eccentricity, the increase in intrinsic location uncertainty with retinal eccentricity, and the prior probability of target presence
and target location in the image. The computational steps of the theory are
as follows.First, the effective prior probability distribution on target location
is computed from the prior and the intrinsic location uncertainty. Second,
the effective amplitude of the target (also dependent on retinal eccentricity) is computed and the target (if present) is added to the background.
Third, template responses are computed at each image location by taking
the dot product of a template (having the shape of target) with the image
and then adding a random sample of internal noise. Fourth, the responses
are correctly normalized by the sum of the internal noise variance and the
estimated variance due to external factors (the background statistics).Fifth,
the normalized responses are summed with the log of the effective prior on
target location to obtain values proportional to the posterior probability.If the
maximum of these values exceeds a criterion, the response is that the target
is present at the location of the maximum. The theory predicts that i) misses
occur more often than false alarms, ii) misses occur further in the periphery
than false alarms, and iii) these asymmetries decrease with increasing target
amplitude. Preliminary results show that the theoretical and human spatial
distribution of errors are similar.&lt;/p&gt;

&lt;p&gt;Walshe, R.C. &amp;amp; Geisler, W.S. (2019). Theory of Covert Search in Noise Backgrounds Correctly Predicts Asymmetrical Spatial Distributions of Misses and False Alarms. Annual meeting of the Vision Sciences Society.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Saccadic Decision Making</title>
      <link>/calenwalshe.github.io/project/saccades/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/calenwalshe.github.io/project/saccades/</guid>
      <description>&lt;p&gt;Saccadic eye movements are the primary vehicle by which human gaze is brought in alignment with vital visual information present in naturalistic scenes. Although numerous studies using the double-step paradigm have demonstrated that saccade preparation is subject to modification under certain conditions, this has yet to be studied directly within a naturalistic scene-viewing context. To reveal characteristic properties of saccade programming during naturalistic scene viewing, we contrasted behavior across three conditions. In the Static condition of the main experiment, double-step targets were presented following a period of stable fixation on a central cross. In a Scene condition, targets were presented while participants actively explored a naturalistic scene. During a Noise condition, targets were presented during active exploration of a 1/f noise-filtered scene. In Experiment 2, we measure saccadic responses in three Static conditions (Uniform, Scene, and Noise) in which the backgrounds are the same as Experiment 1 but scene exploration is no longer permitted. We find that the mechanisms underlying saccade modification generalize to both dynamic conditions. However, we show that a property of saccade programming known as the saccadic dead time (SDT), the interval prior to saccade onset during which a saccade may not be canceled or modified, is lower in the Static task than it is in the dynamic tasks. We also find a trend toward longer SDT in the Scene as compared with Noise conditions. We discuss the implication of these results for computational models of scene viewing, reading, and visual search tasks.&lt;/p&gt;

&lt;p&gt;Walshe, R.C. &amp;amp; Nuthmann, A. (2015). Mechanisms of saccadic decision making while encoding naturalistic scenes. Journal of Vision, 15(21).&lt;/p&gt;

&lt;p&gt;Walshe, R.C. &amp;amp; Nuthmann, A. (2014). Asymmetric control of fixation durations in scene viewing. Vision Research, 100, 38-46.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
