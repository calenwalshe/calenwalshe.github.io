<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cognitive_science | R. Calen Walshe</title>
    <link>/tags/cognitive_science/</link>
      <atom:link href="/tags/cognitive_science/index.xml" rel="self" type="application/rss+xml" />
    <description>cognitive_science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 24 Sep 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>cognitive_science</title>
      <link>/tags/cognitive_science/</link>
    </image>
    
    <item>
      <title>Accurate error rates for binary quadratic classifiers.</title>
      <link>/project/classify/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/project/classify/</guid>
      <description>&lt;p&gt;The classification accuracy between two general Gaussian distributions, and their discriminibality $d&#39;$, are used ubiquitously to express the performance in binary classification and detection tasks. However, these quantities cannot in general be evaluated analytically from the Gaussian parameters. Standard numerical methods may require integration grids that are inefficiently large and fine, may converge slowly, yet miss relevant regions unless tailored case-by-case. We present a new calculation method, based on a transformation of the feature space, that is reliable and fast, and requires no hand-tailoring, for all cases up to 3 dimensions. &lt;a href=&#34;https://github.com/abhranildas/classify&#34;&gt;Our open-source MATLAB implementation of this method&lt;/a&gt; provides a suite of tools related to such classification.&lt;/p&gt;
&lt;p&gt;Das, A., Walshe, R.C., &amp;amp; Geisler, W. (2019). A new method to calculate classification accuracy. Presented at the Annual Meeting of the Vision Sciences Society.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep learning to predict human gaze and human actions in games.</title>
      <link>/project/deep-learning/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/project/deep-learning/</guid>
      <description>&lt;p&gt;Large-scale public datasets have been shown to benefit research in multiple areas of modern artificial intelligence. For decision-making research that requires human data, high-quality datasets serve as important benchmarks to facilitate the development of new methods by providing a common reproducible standard. Many human decision-making tasks require visual attention to obtain high levels of performance. Therefore, measuring eye movements can provide a rich source of information about the strategies that humans use to solve decision-making tasks. Here, we provide a large-scale, high-quality dataset of human actions with simultaneously recorded eye movements while humans play Atari video games. The dataset consists of 117 hours of gameplay data from a diverse set of 20 games, with 8 million action demonstrations and 328 million gaze samples. We introduce a novel form of gameplay, in which the human plays in a semi-frame-by-frame manner. This leads to near-optimal game decisions and game scores that are comparable or better than known human records. We demonstrate the usefulness of the dataset through two simple applications: predicting human gaze and imitating human demonstrated actions. The quality of the data leads to promising results in both tasks. Moreover, using a learned human gaze model to inform imitation learning leads to an 115% increase in game performance. We interpret these results as highlighting the importance of incorporating human visual attention in models of decision making and demonstrating the value of the current dataset to the research community. We hope that the scale and quality of this dataset can provide more opportunities to researchers in the areas of visual attention, imitation learning, and reinforcement learning.&lt;/p&gt;
&lt;p&gt;Zhang, R., Walshe, R.C., Liu, Z., Guan, L., Muller, K.S., Whritner, J.A., Zhang, L., Hayhoe, M. &amp;amp; Ballard, D. (2019). Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset. preprint arXiv. arXiv:1903.06754 (Under review at AAAIâ€™20).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimal search for targets embedded in natural images.</title>
      <link>/project/search/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/search/</guid>
      <description>&lt;p&gt;Searching the environment in a fast and efficient manner is a critical capability for humans and many other animals. Normally, multiple fixations
are used to identify and localize targets. However, in the special case of covert search the target must be identified and localized within a single
fixation. Here we present a theory of covert search that takes into account the statistical variation in background images, the falloff in resolution and
sampling with retinal eccentricity, the increase in intrinsic location uncertainty with retinal eccentricity, and the prior probability of target presence
and target location in the image. The computational steps of the theory are as follows. First, the effective prior probability distribution on target location
is computed from the prior and the intrinsic location uncertainty. Second, the effective amplitude of the target (also dependent on retinal eccentricity) is computed and the target (if present) is added to the background. Third, template responses are computed at each image location by taking the dot product of a template (having the shape of target) with the image and then adding a random sample of internal noise. Fourth, the responses are correctly normalized by the sum of the internal noise variance and the estimated variance due to external factors (the background statistics). Fifth, the normalized responses are summed with the log of the effective prior on target location to obtain values proportional to the posterior probability. If the maximum of these values exceeds a criterion, the response is that the target is present at the location of the maximum. The theory predicts that i) misses occur more often than false alarms, ii) misses occur further in the periphery than false alarms, and iii) these asymmetries decrease with increasing target amplitude. Preliminary results show that the theoretical and human spatial distribution of errors are similar.&lt;/p&gt;
&lt;p&gt;Walshe, R.C. &amp;amp; Geisler, W.S. (2019). Theory of Covert Search in Noise Backgrounds Correctly Predicts Asymmetrical Spatial Distributions of Misses and False Alarms. Annual meeting of the Vision Sciences Society. Poster available &lt;a href=&#34;https://calenwalshe.com/files/vss_2019_search_poster.pdf&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Technical Report (2019). A theory of visual search for foveated visual systems.  Report available &lt;a href=&#34;https://calenwalshe.com/files/tech_report_nov_1_2019.pdf&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
